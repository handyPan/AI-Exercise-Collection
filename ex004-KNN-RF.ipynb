{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# Author: Xiaopeng Pan\n",
    "# ID: 1129446\n",
    "# Purpose: Assignment 3\n",
    "# Date: August 5, 2020\n",
    "\n",
    "# import basic packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os                   # to list the images\n",
    "import shutil               # to remove the folder that holds the resized images\n",
    "from PIL import Image       # to resize the 64 x 64 images to 32 x 32\n",
    "from pprint import pprint   # to print parameters of the model\n",
    "import pickle               # to save and load pickle files\n",
    "\n",
    "# import sklearn packages \n",
    "from sklearn.model_selection import train_test_split      # to split the whole dataset to train and test\n",
    "from sklearn.model_selection import StratifiedKFold       # to train the CNN model by cross validation\n",
    "from sklearn.neighbors import KNeighborsClassifier        # to create the KNN model\n",
    "from sklearn.ensemble import RandomForestClassifier       # to create the RF model\n",
    "from sklearn.model_selection import RandomizedSearchCV    # to use random search\n",
    "from sklearn.model_selection import GridSearchCV          # to use grid search\n",
    "\n",
    "# to evaluate the performance\n",
    "from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,classification_report,confusion_matrix\n",
    "\n",
    "# import keras package to create the CNN model\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "\n",
    "import warnings   # to disable warning\n",
    "warnings.filterwarnings('ignore')     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 1**  \n",
    "Load the dataset for all three classes and resize each image to (32 x 32). Apply the required pre-processing steps to employ the data into Machine Learning / Deep Learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./DS/resized is removed.\n",
      "./DS/resized is created.\n",
      "Images have been resized to 32 x 32 and saved to ./DS/resized\n"
     ]
    }
   ],
   "source": [
    "# set the paths of datasets\n",
    "dataset_root_path = './DS'\n",
    "dataset_resized_path = './DS/resized'\n",
    "\n",
    "# if the resized folder exists, remove it\n",
    "if os.path.exists(dataset_resized_path):\n",
    "    shutil.rmtree(dataset_resized_path)\n",
    "    print(dataset_resized_path + \" is removed.\")\n",
    "\n",
    "# get the list of images \n",
    "file_list = os.listdir(dataset_root_path)\n",
    "\n",
    "# create the resized folder \n",
    "os.mkdir(dataset_resized_path)\n",
    "print(dataset_resized_path + \" is created.\")\n",
    "\n",
    "# resize all the images to 32 x 32 and save them to the resized folder \n",
    "for file_name in file_list:\n",
    "    img = Image.open(dataset_root_path + \"/\" + file_name)\n",
    "    img_resized = img.resize((32,32))\n",
    "    img_resized.save(dataset_resized_path + \"/\" + file_name)\n",
    "    \n",
    "print(\"Images have been resized to 32 x 32 and saved to \"+ dataset_resized_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 images have been processed \n",
      "\n",
      "Attributes are:  int32 \n",
      " [[[[100 100 100]\n",
      "   [100 100 100]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [100 100 100]\n",
      "   [102 102 102]\n",
      "   [102 102 102]]\n",
      "\n",
      "  [[105 105 105]\n",
      "   [103 103 103]\n",
      "   [100 100 100]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [100 100 100]\n",
      "   [ 99  99  99]]\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [100 100 100]\n",
      "   [ 99  99  99]\n",
      "   [ 98  98  98]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [ 99  99  99]\n",
      "   [ 99  99  99]\n",
      "   [ 99  99  99]]\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [100 100 100]\n",
      "   [100 100 100]\n",
      "   [100 100 100]]\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [102 102 102]\n",
      "   [103 103 103]]]\n",
      "\n",
      "\n",
      " [[[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [100 100 100]\n",
      "   [100 100 100]\n",
      "   [100 100 100]]\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [100 100 100]\n",
      "   [100 100 100]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [100 100 100]\n",
      "   [101 101 101]\n",
      "   [102 102 102]]]\n",
      "\n",
      "\n",
      " [[[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [100 100 100]\n",
      "   [100 100 100]\n",
      "   [100 100 100]]\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [100 100 100]\n",
      "   [100 100 100]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [100 100 100]\n",
      "   [101 101 101]\n",
      "   [102 102 102]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 20  20  20]\n",
      "   [ 35  35  35]\n",
      "   [ 16  16  16]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 21  21  21]\n",
      "   [ 30  30  30]\n",
      "   [ 19  19  19]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 24  24  24]\n",
      "   [ 24  24  24]\n",
      "   [ 21  21  21]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 27  27  27]\n",
      "   [ 22  22  22]\n",
      "   [ 19  19  19]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 29  29  29]\n",
      "   [ 33  33  33]\n",
      "   [ 15  15  15]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 12  12  12]\n",
      "   [ 39  39  39]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]]\n",
      "\n",
      "\n",
      " [[[ 15  15  15]\n",
      "   [ 27  27  27]\n",
      "   [ 27  27  27]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 34  34  34]\n",
      "   [ 25  25  25]\n",
      "   [ 17  17  17]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 33  33  33]\n",
      "   [ 19  19  19]\n",
      "   [ 21  21  21]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 31  31  31]\n",
      "   [ 17  17  17]\n",
      "   [ 20  20  20]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 33  33  33]\n",
      "   [ 25  25  25]\n",
      "   [ 19  19  19]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 18  18  18]\n",
      "   [ 32  32  32]\n",
      "   [ 34  34  34]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]]\n",
      "\n",
      "\n",
      " [[[ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]]]\n",
      "\n",
      "Labels are:  int32 \n",
      " [[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [2]\n",
      " [2]\n",
      " [2]]\n"
     ]
    }
   ],
   "source": [
    "# generate the dataset to be processed\n",
    "X = np.zeros((1500,32,32,3),dtype=np.int32)\n",
    "Y = np.zeros((1500,1),dtype=np.int32)\n",
    "\n",
    "file_index = 0\n",
    "for file_name in file_list:\n",
    "    img_path = dataset_resized_path + \"/\" + file_name\n",
    "    img = image.load_img(img_path, target_size=(32, 32))\n",
    "    img_value = image.img_to_array(img)\n",
    "    img_value = np.expand_dims(img_value, axis=0)\n",
    "    X[file_index] = img_value # assign image attribute values to X array\n",
    "    if \"Abdomen\" in file_name:\n",
    "        Y[file_index] = 0 # assign class values to y array\n",
    "    elif \"Chest\" in file_name:\n",
    "        Y[file_index] = 1\n",
    "    elif \"Head\" in file_name:\n",
    "        Y[file_index] = 2\n",
    "    file_index = file_index + 1\n",
    "print(file_index,\"images have been processed \")\n",
    "print(\"\\nAttributes are: \",X.dtype,\"\\n\",X)\n",
    "print(\"\\nLabels are: \",Y.dtype,\"\\n\",Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xTrain =\n",
      " [[[[ 96  96  96]\n",
      "   [ 98  98  98]\n",
      "   [102 102 102]\n",
      "   ...\n",
      "   [ 98  98  98]\n",
      "   [ 99  99  99]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[106 106 106]\n",
      "   [103 103 103]\n",
      "   [100 100 100]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [100 100 100]\n",
      "   [100 100 100]]\n",
      "\n",
      "  [[104 104 104]\n",
      "   [102 102 102]\n",
      "   [ 99  99  99]\n",
      "   ...\n",
      "   [104 104 104]\n",
      "   [102 102 102]\n",
      "   [100 100 100]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[102 102 102]\n",
      "   [102 102 102]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[102 102 102]\n",
      "   [102 102 102]\n",
      "   [102 102 102]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[102 102 102]\n",
      "   [102 102 102]\n",
      "   [102 102 102]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]]\n",
      "\n",
      "\n",
      " [[[ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 28  28  28]\n",
      "   [ 22  22  22]\n",
      "   [ 21  21  21]\n",
      "   ...\n",
      "   [ 21  21  21]\n",
      "   [ 22  22  22]\n",
      "   [ 28  28  28]]\n",
      "\n",
      "  [[ 28  28  28]\n",
      "   [ 25  25  25]\n",
      "   [ 23  23  23]\n",
      "   ...\n",
      "   [ 23  23  23]\n",
      "   [ 25  25  25]\n",
      "   [ 24  24  24]]\n",
      "\n",
      "  [[ 27  27  27]\n",
      "   [ 28  28  28]\n",
      "   [ 26  26  26]\n",
      "   ...\n",
      "   [ 26  26  26]\n",
      "   [ 27  27  27]\n",
      "   [ 21  21  21]]]\n",
      "\n",
      "\n",
      " [[[ 96  96  96]\n",
      "   [ 99  99  99]\n",
      "   [102 102 102]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[102 102 102]\n",
      "   [102 102 102]\n",
      "   [102 102 102]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[104 104 104]\n",
      "   [102 102 102]\n",
      "   [ 99  99  99]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[100 100 100]\n",
      "   [100 100 100]\n",
      "   [100 100 100]\n",
      "   ...\n",
      "   [100 100 100]\n",
      "   [100 100 100]\n",
      "   [100 100 100]]\n",
      "\n",
      "  [[100 100 100]\n",
      "   [100 100 100]\n",
      "   [100 100 100]\n",
      "   ...\n",
      "   [100 100 100]\n",
      "   [100 100 100]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[100 100 100]\n",
      "   [100 100 100]\n",
      "   [100 100 100]\n",
      "   ...\n",
      "   [100 100 100]\n",
      "   [101 101 101]\n",
      "   [102 102 102]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 20  20  20]\n",
      "   [ 61  61  61]\n",
      "   ...\n",
      "   [ 87  87  87]\n",
      "   [ 31  31  31]\n",
      "   [ 23  23  23]]\n",
      "\n",
      "  [[ 24  24  24]\n",
      "   [ 26  26  26]\n",
      "   [ 29  29  29]\n",
      "   ...\n",
      "   [ 53  53  53]\n",
      "   [ 21  21  21]\n",
      "   [ 24  24  24]]\n",
      "\n",
      "  [[ 24  24  24]\n",
      "   [ 29  29  29]\n",
      "   [ 16  16  16]\n",
      "   ...\n",
      "   [ 16  16  16]\n",
      "   [ 19  19  19]\n",
      "   [ 25  25  25]]]\n",
      "\n",
      "\n",
      " [[[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[100 100 100]\n",
      "   [101 101 101]\n",
      "   [102 102 102]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[100 100 100]\n",
      "   [101 101 101]\n",
      "   [102 102 102]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [102 102 102]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]]\n",
      "\n",
      "\n",
      " [[[ 30  30  30]\n",
      "   [ 22  22  22]\n",
      "   [ 19  19  19]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 20  20  20]\n",
      "   [ 21  21  21]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 20  20  20]\n",
      "   [ 26  26  26]\n",
      "   [ 29  29  29]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 19  19  19]\n",
      "   [ 36  36  36]\n",
      "   [ 21  21  21]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 17  17  17]\n",
      "   [ 42  42  42]\n",
      "   [ 26  26  26]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 33  33  33]\n",
      "   [ 13  13  13]\n",
      "   [ 24  24  24]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]]]\n",
      "\n",
      "xTest=\n",
      " [[[[ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 26  26  26]\n",
      "   [ 27  27  27]\n",
      "   [ 27  27  27]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 26  26  26]\n",
      "   [ 28  28  28]\n",
      "   [ 27  27  27]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]\n",
      "\n",
      "  [[ 26  26  26]\n",
      "   [ 26  26  26]\n",
      "   [ 26  26  26]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]]]\n",
      "\n",
      "\n",
      " [[[126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   ...\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]]\n",
      "\n",
      "  [[126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   ...\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]]\n",
      "\n",
      "  [[126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   ...\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[125 125 125]\n",
      "   [125 125 125]\n",
      "   [125 125 125]\n",
      "   ...\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]]\n",
      "\n",
      "  [[125 125 125]\n",
      "   [125 125 125]\n",
      "   [125 125 125]\n",
      "   ...\n",
      "   [127 127 127]\n",
      "   [125 125 125]\n",
      "   [125 125 125]]\n",
      "\n",
      "  [[125 125 125]\n",
      "   [125 125 125]\n",
      "   [125 125 125]\n",
      "   ...\n",
      "   [127 127 127]\n",
      "   [125 125 125]\n",
      "   [123 123 123]]]\n",
      "\n",
      "\n",
      " [[[126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   ...\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]]\n",
      "\n",
      "  [[126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   ...\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]]\n",
      "\n",
      "  [[126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   ...\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[129 129 129]\n",
      "   [125 125 125]\n",
      "   [122 122 122]\n",
      "   ...\n",
      "   [139 139 139]\n",
      "   [129 129 129]\n",
      "   [113 113 113]]\n",
      "\n",
      "  [[126 126 126]\n",
      "   [125 125 125]\n",
      "   [123 123 123]\n",
      "   ...\n",
      "   [115 115 115]\n",
      "   [125 125 125]\n",
      "   [135 135 135]]\n",
      "\n",
      "  [[121 121 121]\n",
      "   [124 124 124]\n",
      "   [128 128 128]\n",
      "   ...\n",
      "   [121 121 121]\n",
      "   [125 125 125]\n",
      "   [126 126 126]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[103 103 103]\n",
      "   [102 102 102]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [ 98  98  98]\n",
      "   [ 96  96  96]]\n",
      "\n",
      "  [[103 103 103]\n",
      "   [102 102 102]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [ 98  98  98]\n",
      "   [101 101 101]\n",
      "   [105 105 105]]\n",
      "\n",
      "  [[102 102 102]\n",
      "   [102 102 102]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [ 99  99  99]\n",
      "   [103 103 103]\n",
      "   [107 107 107]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]\n",
      "\n",
      "  [[101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   ...\n",
      "   [101 101 101]\n",
      "   [101 101 101]\n",
      "   [101 101 101]]]\n",
      "\n",
      "\n",
      " [[[ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   [ 27  27  27]\n",
      "   ...\n",
      "   [ 26  26  26]\n",
      "   [ 26  26  26]\n",
      "   [ 26  26  26]]\n",
      "\n",
      "  [[ 26  26  26]\n",
      "   [ 25  25  25]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 23  23  23]\n",
      "   [ 23  23  23]\n",
      "   [ 22  22  22]]\n",
      "\n",
      "  [[ 27  27  27]\n",
      "   [ 27  27  27]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 24  24  24]\n",
      "   [ 24  24  24]\n",
      "   [ 24  24  24]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 25  25  25]\n",
      "   [ 26  26  26]\n",
      "   [ 31  31  31]\n",
      "   ...\n",
      "   [ 22  22  22]\n",
      "   [ 19  19  19]\n",
      "   [ 28  28  28]]\n",
      "\n",
      "  [[ 24  24  24]\n",
      "   [ 28  28  28]\n",
      "   [ 25  25  25]\n",
      "   ...\n",
      "   [ 28  28  28]\n",
      "   [ 17  17  17]\n",
      "   [ 31  31  31]]\n",
      "\n",
      "  [[ 26  26  26]\n",
      "   [ 25  25  25]\n",
      "   [ 18  18  18]\n",
      "   ...\n",
      "   [ 25  25  25]\n",
      "   [ 24  24  24]\n",
      "   [ 26  26  26]]]\n",
      "\n",
      "\n",
      " [[[126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   ...\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]]\n",
      "\n",
      "  [[126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   ...\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]]\n",
      "\n",
      "  [[126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   ...\n",
      "   [126 126 126]\n",
      "   [126 126 126]\n",
      "   [126 126 126]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[126 126 126]\n",
      "   [128 128 128]\n",
      "   [127 127 127]\n",
      "   ...\n",
      "   [125 125 125]\n",
      "   [123 123 123]\n",
      "   [124 124 124]]\n",
      "\n",
      "  [[128 128 128]\n",
      "   [130 130 130]\n",
      "   [129 129 129]\n",
      "   ...\n",
      "   [124 124 124]\n",
      "   [121 121 121]\n",
      "   [126 126 126]]\n",
      "\n",
      "  [[124 124 124]\n",
      "   [125 125 125]\n",
      "   [123 123 123]\n",
      "   ...\n",
      "   [127 127 127]\n",
      "   [130 130 130]\n",
      "   [127 127 127]]]]\n",
      "\n",
      "yTrain=\n",
      " [[0]\n",
      " [2]\n",
      " [0]\n",
      " ...\n",
      " [2]\n",
      " [0]\n",
      " [2]]\n",
      "\n",
      "yTest=\n",
      " [[2]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [2]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [2]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# dataset splitting \n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size=0.2, random_state=47)\n",
    "# show the train and test datasets for both X and Y after splitting\n",
    "print(\"\\nxTrain =\\n\",xTrain)\n",
    "print(\"\\nxTest=\\n\",xTest)\n",
    "print(\"\\nyTrain=\\n\",yTrain)\n",
    "print(\"\\nyTest=\\n\",yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2**  \n",
    "Construct a Convolutional Neural Network (CNN) architecture to extract features from the images. (HINT: Extract features for train and test set separately. Extract the features constructed by the convolutional layers from an intermediate dense layer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 13, 13, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               295040    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 322,883\n",
      "Trainable params: 322,883\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the CNN model \n",
    "img_rows = 32\n",
    "img_cols = 32\n",
    "channel_number = 3\n",
    "activation_function='relu'\n",
    "\n",
    "def getModel():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, kernel_size = (3, 3), activation=activation_function, input_shape=(img_rows, img_cols, channel_number)))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Conv2D(64, kernel_size=(3,3), activation=activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation=activation_function))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(64, activation=activation_function))\n",
    "    model.add(Dense(3, activation = 'softmax'))\n",
    "    model.compile(optimizer='RMSprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "model_cnn = getModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for fold 1\n",
      "Epoch 1/10\n",
      "960/960 [==============================] - 11s 12ms/step - loss: 1.5829 - accuracy: 0.8021 - val_loss: 0.0458 - val_accuracy: 0.9833\n",
      "Epoch 2/10\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.5540 - accuracy: 0.9594 - val_loss: 0.2124 - val_accuracy: 0.9667\n",
      "Epoch 3/10\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.7168 - accuracy: 0.9563 - val_loss: 0.6625 - val_accuracy: 0.9625\n",
      "Epoch 4/10\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.5890 - accuracy: 0.9792 - val_loss: 0.2279 - val_accuracy: 0.9917\n",
      "Epoch 5/10\n",
      "960/960 [==============================] - 15s 16ms/step - loss: 0.7535 - accuracy: 0.9563 - val_loss: 0.2407 - val_accuracy: 0.9792\n",
      "Epoch 6/10\n",
      "960/960 [==============================] - 15s 15ms/step - loss: 0.2856 - accuracy: 0.9854 - val_loss: 0.0395 - val_accuracy: 0.9958\n",
      "Epoch 7/10\n",
      "960/960 [==============================] - 15s 15ms/step - loss: 0.6674 - accuracy: 0.9698 - val_loss: 0.3685 - val_accuracy: 0.9375\n",
      "Epoch 8/10\n",
      "960/960 [==============================] - 18s 19ms/step - loss: 0.6071 - accuracy: 0.9708 - val_loss: 1.8914 - val_accuracy: 0.8875\n",
      "Epoch 9/10\n",
      "960/960 [==============================] - 17s 18ms/step - loss: 0.5620 - accuracy: 0.9802 - val_loss: 0.0120 - val_accuracy: 0.9958\n",
      "Epoch 10/10\n",
      "960/960 [==============================] - 17s 18ms/step - loss: 0.6125 - accuracy: 0.9740 - val_loss: 0.2401 - val_accuracy: 0.9708\n",
      "Results for fold 2\n",
      "Epoch 1/10\n",
      "960/960 [==============================] - 18s 19ms/step - loss: 0.3344 - accuracy: 0.9812 - val_loss: 0.3950 - val_accuracy: 0.9542\n",
      "Epoch 2/10\n",
      "960/960 [==============================] - 17s 18ms/step - loss: 0.4502 - accuracy: 0.9833 - val_loss: 8.9407e-09 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "960/960 [==============================] - 18s 18ms/step - loss: 0.3641 - accuracy: 0.9844 - val_loss: 4.9671e-10 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "960/960 [==============================] - 19s 20ms/step - loss: 0.2950 - accuracy: 0.9771 - val_loss: 4.2220e-08 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "960/960 [==============================] - 23s 24ms/step - loss: 0.3507 - accuracy: 0.9833 - val_loss: 5.8243e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "960/960 [==============================] - 22s 23ms/step - loss: 0.5431 - accuracy: 0.9760 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "960/960 [==============================] - 20s 21ms/step - loss: 0.5311 - accuracy: 0.9823 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "960/960 [==============================] - 18s 19ms/step - loss: 0.6724 - accuracy: 0.9823 - val_loss: 0.0521 - val_accuracy: 0.9917\n",
      "Epoch 9/10\n",
      "960/960 [==============================] - 18s 19ms/step - loss: 0.3470 - accuracy: 0.9885 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "960/960 [==============================] - 17s 18ms/step - loss: 0.3797 - accuracy: 0.9906 - val_loss: 2.4062 - val_accuracy: 0.6250\n",
      "Results for fold 3\n",
      "Epoch 1/10\n",
      "960/960 [==============================] - 17s 18ms/step - loss: 0.7040 - accuracy: 0.9781 - val_loss: 0.0792 - val_accuracy: 0.9833\n",
      "Epoch 2/10\n",
      "960/960 [==============================] - 18s 19ms/step - loss: 0.2404 - accuracy: 0.9885 - val_loss: 0.0337 - val_accuracy: 0.9958\n",
      "Epoch 3/10\n",
      "960/960 [==============================] - 17s 18ms/step - loss: 0.2012 - accuracy: 0.9927 - val_loss: 0.0132 - val_accuracy: 0.9958\n",
      "Epoch 4/10\n",
      "960/960 [==============================] - 17s 18ms/step - loss: 0.3424 - accuracy: 0.9896 - val_loss: 0.0400 - val_accuracy: 0.9958\n",
      "Epoch 5/10\n",
      "960/960 [==============================] - 17s 18ms/step - loss: 0.1873 - accuracy: 0.9937 - val_loss: 0.0400 - val_accuracy: 0.9958\n",
      "Epoch 6/10\n",
      "960/960 [==============================] - 19s 19ms/step - loss: 0.3813 - accuracy: 0.9854 - val_loss: 0.0704 - val_accuracy: 0.9875\n",
      "Epoch 7/10\n",
      "960/960 [==============================] - 20s 21ms/step - loss: 0.0281 - accuracy: 0.9990 - val_loss: 0.0478 - val_accuracy: 0.9958\n",
      "Epoch 8/10\n",
      "960/960 [==============================] - 20s 21ms/step - loss: 0.3832 - accuracy: 0.9937 - val_loss: 0.0665 - val_accuracy: 0.9917\n",
      "Epoch 9/10\n",
      "960/960 [==============================] - 19s 20ms/step - loss: 0.3419 - accuracy: 0.9896 - val_loss: 0.0505 - val_accuracy: 0.9958\n",
      "Epoch 10/10\n",
      "960/960 [==============================] - 20s 21ms/step - loss: 0.0856 - accuracy: 0.9937 - val_loss: 0.0603 - val_accuracy: 0.9958\n",
      "Results for fold 4\n",
      "Epoch 1/10\n",
      "960/960 [==============================] - 20s 21ms/step - loss: 0.5193 - accuracy: 0.9875 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "960/960 [==============================] - 19s 20ms/step - loss: 0.1324 - accuracy: 0.9948 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "960/960 [==============================] - 18s 19ms/step - loss: 0.6865 - accuracy: 0.9885 - val_loss: 0.0057 - val_accuracy: 0.9958\n",
      "Epoch 4/10\n",
      "960/960 [==============================] - 16s 17ms/step - loss: 0.2012 - accuracy: 0.9917 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "960/960 [==============================] - 16s 16ms/step - loss: 0.2711 - accuracy: 0.9917 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "960/960 [==============================] - 16s 17ms/step - loss: 0.0295 - accuracy: 0.9969 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "960/960 [==============================] - 17s 18ms/step - loss: 0.1680 - accuracy: 0.9969 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "960/960 [==============================] - 16s 17ms/step - loss: 0.2360 - accuracy: 0.9896 - val_loss: 4.9671e-10 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "960/960 [==============================] - 16s 16ms/step - loss: 0.1776 - accuracy: 0.9927 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "960/960 [==============================] - 16s 17ms/step - loss: 0.3026 - accuracy: 0.9906 - val_loss: 4.9671e-10 - val_accuracy: 1.0000\n",
      "Results for fold 5\n",
      "Epoch 1/10\n",
      "960/960 [==============================] - 18s 19ms/step - loss: 0.3137 - accuracy: 0.9885 - val_loss: 1.0703e-04 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "960/960 [==============================] - 19s 20ms/step - loss: 0.1071 - accuracy: 0.9917 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "960/960 [==============================] - 19s 20ms/step - loss: 0.1119 - accuracy: 0.9979 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "960/960 [==============================] - 19s 19ms/step - loss: 0.1174 - accuracy: 0.9917 - val_loss: 1.4901e-09 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "960/960 [==============================] - 19s 20ms/step - loss: 0.0932 - accuracy: 0.9948 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "960/960 [==============================] - 19s 20ms/step - loss: 0.2722 - accuracy: 0.9906 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "960/960 [==============================] - 19s 20ms/step - loss: 0.0814 - accuracy: 0.9948 - val_loss: 0.0293 - val_accuracy: 0.9958\n",
      "Epoch 8/10\n",
      "960/960 [==============================] - 19s 19ms/step - loss: 0.1303 - accuracy: 0.9958 - val_loss: 0.2831 - val_accuracy: 0.9958\n",
      "Epoch 9/10\n",
      "960/960 [==============================] - 20s 21ms/step - loss: 0.3164 - accuracy: 0.9958 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "960/960 [==============================] - 20s 21ms/step - loss: 0.2087 - accuracy: 0.9917 - val_loss: 1.6590e-07 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train the CNN model with Cross Validation\n",
    "epochs=10\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "skf.get_n_splits(xTrain, yTrain)\n",
    "foldNum=0\n",
    "for train_index, val_index in skf.split(xTrain, yTrain):\n",
    "    foldNum+=1\n",
    "    print(\"Results for fold\",foldNum)\n",
    "    X_train, X_val = X.reshape(X.shape[0],32,32,3)[train_index], X.reshape(X.shape[0],32,32,3)[val_index]\n",
    "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "    Y_train = to_categorical(Y_train, 3)\n",
    "    Y_val = to_categorical(Y_val, 3)\n",
    "\n",
    "    history = model_cnn.fit(X_train, Y_train, \n",
    "                        validation_data = (X_val, Y_val), \n",
    "                        epochs=epochs,\n",
    "                        batch_size=1\n",
    "                        )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features of the Train dataset are: 1200 x 64\n",
      "tf.Tensor(\n",
      "[[ 28.552565   0.         0.       ...   0.         0.         0.      ]\n",
      " [ 61.33877    0.         0.       ... 667.88214    0.         0.      ]\n",
      " [110.06753    0.         0.       ...   0.         0.         0.      ]\n",
      " ...\n",
      " [152.26851    0.         0.       ... 724.10803    0.         0.      ]\n",
      " [ 70.454025   0.         0.       ...   0.         0.         0.      ]\n",
      " [ 57.47207    0.         0.       ... 671.68115    0.         0.      ]], shape=(1200, 64), dtype=float32)\n",
      "Features of the Test dataset are: 300 x 64\n",
      "tf.Tensor(\n",
      "[[ 68.461044   0.         0.       ... 406.19528    0.         0.      ]\n",
      " [ 54.712166   0.         0.       ...  59.864754   0.         0.      ]\n",
      " [ 85.70481    0.         0.       ... 154.24258    0.         0.      ]\n",
      " ...\n",
      " [ 74.266365   0.         0.       ...   0.         0.         0.      ]\n",
      " [ 41.729366   0.         0.       ... 448.75974    0.         0.      ]\n",
      " [ 87.46386    0.         0.       ... 172.67525    0.         0.      ]], shape=(300, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# extract features for train and test datasets\n",
    "features_extractor = keras.Model(inputs=model_cnn.inputs,\n",
    "                        outputs=model_cnn.layers[9].output) # the features are taken from output of layers[9]\n",
    "features_xTrain = features_extractor(xTrain)\n",
    "features_xTest = features_extractor(xTest)\n",
    "\n",
    "print(\"Features of the Train dataset are:\",len(features_xTrain),\"x\",len(features_xTrain[0]))\n",
    "print(features_xTrain)\n",
    "print(\"Features of the Test dataset are:\",len(features_xTest),\"x\",len(features_xTest[0]))\n",
    "print(features_xTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3**  \n",
    "Apply the K-Nearest Neighbor (KNN) algorithm to the extracted features from CNN and find the optimal value of K. The value of K can be considered as [3, 5, 7, 9]. Determine the performance of the model using an appropriate performance metric. Draw a graph of K values and their corresponding performance in order to represent your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Abdomen images: 102\n",
      "Number of Chest images: 105\n",
      "Number of Head images: 93\n",
      "\n",
      "For K = 3\n",
      "Accuracy = 0.9966666666666667\n",
      "Confusion Matrix =\n",
      " [[102   0   0]\n",
      " [  0 105   0]\n",
      " [  0   1  92]]\n",
      "For K = 5\n",
      "Accuracy = 0.9933333333333333\n",
      "Confusion Matrix =\n",
      " [[102   0   0]\n",
      " [  0 105   0]\n",
      " [  1   1  91]]\n",
      "For K = 7\n",
      "Accuracy = 0.9933333333333333\n",
      "Confusion Matrix =\n",
      " [[102   0   0]\n",
      " [  0 105   0]\n",
      " [  1   1  91]]\n",
      "For K = 9\n",
      "Accuracy = 0.9933333333333333\n",
      "Confusion Matrix =\n",
      " [[102   0   0]\n",
      " [  0 105   0]\n",
      " [  1   1  91]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the train and test datasets for KNN\n",
    "xTrain_knn = features_xTrain.numpy()\n",
    "yTrain_knn = yTrain.reshape(-1)\n",
    "xTest_knn = features_xTest.numpy()\n",
    "yTest_knn = yTest.reshape(-1)\n",
    "\n",
    "# for each class, print the number of images in the test set \n",
    "num_Abdomen = 0\n",
    "num_Chest = 0\n",
    "num_Head = 0\n",
    "\n",
    "for y in yTest_knn:\n",
    "    if y==0:\n",
    "        num_Abdomen+=1\n",
    "    elif y==1:\n",
    "        num_Chest+=1\n",
    "    elif y==2:\n",
    "        num_Head+=1\n",
    "print(\"Number of Abdomen images:\",num_Abdomen)\n",
    "print(\"Number of Chest images:\",num_Chest)\n",
    "print(\"Number of Head images:\",num_Head)\n",
    "print()\n",
    "\n",
    "# define the K values and accuracy values\n",
    "K=[3,5,7,9]\n",
    "accuracy_knn=[]\n",
    "\n",
    "for k in K:\n",
    "    model_knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    model_knn.fit(xTrain_knn, yTrain_knn)\n",
    "    \n",
    "    # save the model to pickle file\n",
    "    pkl_filename = \"Xiaopeng Pan_1129446_knn_k_\"+str(k)+\".pkl\"\n",
    "    with open(pkl_filename, 'wb') as file:\n",
    "        pickle.dump(model_knn, file)\n",
    "    \n",
    "    # Load the model from pickle file\n",
    "    with open(pkl_filename, 'rb') as file:\n",
    "        pickle_model_knn = pickle.load(file)\n",
    "    prediction_knn= pickle_model_knn.predict(xTest_knn)\n",
    "    \n",
    "    # print the performance evaluation\n",
    "    print(\"For K =\",k)\n",
    "    print(\"Accuracy =\",accuracy_score(yTest_knn, prediction_knn))\n",
    "    print(\"Confusion Matrix =\\n\",confusion_matrix(yTest_knn, prediction_knn))\n",
    "    accuracy_knn.append(accuracy_score(yTest_knn, prediction_knn))\n",
    "\n",
    "# plot the performance graph\n",
    "plt.plot(K,accuracy_knn)\n",
    "plt.title('Accuracy vs K')\n",
    "plt.xlabel('Number of Neighbors (K)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4**  \n",
    "Apply Random Forest (RF) algorithm to the extracted features from CNN. Tune at least two hyperparameters using random search. Determine the model's optimal performance, the confusion matrix, and the value of hyperparameters producing the optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of to choose:\n",
      "{'max_depth': [10, 20, 30, 40, 50, None],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [100, 200, 300, 400, 500]}\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   35.5s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters found are:\n",
      "{'max_depth': 50,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'n_estimators': 100}\n",
      "\n",
      "The hyperparameters of the optimal model are:\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 50, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Accuracy: \n",
      " 0.9966666666666667\n",
      "\n",
      "Confusion Matrix: \n",
      " [[102   0   0]\n",
      " [  0 105   0]\n",
      " [  1   0  92]]\n"
     ]
    }
   ],
   "source": [
    "# define the train and test datasets for RF and random search\n",
    "xTrain_rf = features_xTrain.numpy()\n",
    "yTrain_rf = yTrain.reshape(-1)\n",
    "xTest_rf = features_xTest.numpy()\n",
    "yTest_rf = yTest.reshape(-1)\n",
    "\n",
    "# define the hyperparameters to tune\n",
    "# maximum depth of a tree\n",
    "max_depth = [10,20,30,40,50]\n",
    "max_depth.append(None)\n",
    "# minimum samples at each leaf node\n",
    "min_samples_leaf = [1,2,4]\n",
    "# minimum samples to split a node\n",
    "min_samples_split = [2,5,10]\n",
    "# number of trees in the random forest \n",
    "n_estimators = [100,200,300,400,500]\n",
    "\n",
    "# create the parameters grid\n",
    "param_grid = {'max_depth':max_depth,\n",
    "              'min_samples_leaf':min_samples_leaf,\n",
    "              'min_samples_split':min_samples_split,\n",
    "              'n_estimators':n_estimators}\n",
    "\n",
    "# print the parameters for above model\n",
    "print(\"Parameters of to choose:\")\n",
    "pprint(param_grid)\n",
    "\n",
    "# create the random forest model\n",
    "model_rf = RandomForestClassifier()\n",
    "# create the random search model\n",
    "model_rs = RandomizedSearchCV(estimator = model_rf, param_distributions = param_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# fit the random search model\n",
    "model_rs.fit(xTrain_rf,yTrain_rf)\n",
    "# print the best parameters\n",
    "print(\"The best hyperparameters found are:\")\n",
    "pprint(model_rs.best_params_)\n",
    "\n",
    "# save the optimal model to pickle file\n",
    "pkl_filename = \"Xiaopeng Pan_1129446_RF.pkl\"\n",
    "with open(pkl_filename, 'wb') as file:\n",
    "    pickle.dump(model_rs.best_estimator_, file)\n",
    "\n",
    "# Load the model from pickle file\n",
    "with open(pkl_filename, 'rb') as file:\n",
    "    model_rs_optimal = pickle.load(file)\n",
    "# print the hyperparameters of the optimal model\n",
    "print(\"\\nThe hyperparameters of the optimal model are:\")\n",
    "print(model_rs_optimal.get_params())\n",
    "\n",
    "# use the optimal model to predict the test data\n",
    "prediction_rs_optimal = model_rs_optimal.predict(xTest_rf)\n",
    "# print the performance of the optimal model\n",
    "accuracy_rs_optimal = accuracy_score(yTest_rf,prediction_rs_optimal)\n",
    "confusionMatrix_rs_optimal = confusion_matrix(yTest_rf,prediction_rs_optimal)\n",
    "print(\"\\nAccuracy: \\n\", accuracy_rs_optimal)\n",
    "print(\"\\nConfusion Matrix: \\n\", confusionMatrix_rs_optimal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5**  \n",
    "Report the performance of each model and explain your results. (eg. overfitting, underfitting, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the separate \"Xiaopeng Pan_1129446_Report\" file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
